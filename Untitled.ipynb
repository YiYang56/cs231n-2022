{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NearestNeighbor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        self.Xtr = X\n",
    "        self.ytr = y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        num_test = X.shape[0]\n",
    "        Ypred = np.zeros(num_test, dtype=self.ytr.dtype)\n",
    "        \n",
    "        for i in xrange(num_test):\n",
    "            distances = np.sum(np.abs(self.Xtr - X[i,:]), axis=1)\n",
    "            min_index = np.argmin(distances)\n",
    "            Ypred = self.ytr(min_index)\n",
    "            \n",
    "        return Ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![distance](./fig/1.png)\n",
    "\n",
    "### 当向量中的每个元素都有实际意义时，L1可能优于L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 超参数设置策略\n",
    "\n",
    "## dataset划分\n",
    "![split](./fig/2.png)\n",
    "\n",
    "## K-fold\n",
    "![KF](./fig/3.png)\n",
    "### tips：K-fold仅适用于较小的数据集，考虑到算力开销，通常不用于深度学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svm loss and others\n",
    "![examp](./fig/lossexamp.png)\n",
    "\n",
    "\n",
    "### 当初始化W取值均较小时，首轮svm loss应约等于C-1（debug策略）\n",
    "### svm loss思想：正确的比错误的得分要高出一个安全边界\n",
    "\n",
    "\n",
    "## softmax loss\n",
    "![softmax](./fig/softmax.png)\n",
    "\n",
    "### 当初始化W取值均较小时，首轮softmax loss应约等于log（C）（debug策略）\n",
    "\n",
    "\n",
    "### 正则项：降低模型复杂度（幂次）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 反向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![computationgraph](./fig/computation_graphs.png)\n",
    "\n",
    "### 反向传播是链式法制的递归调用\n",
    "\n",
    "![sigmoid gate](./fig/sigate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积与池化\n",
    "\n",
    "### 卷积的一大好处:可以保留空间结构\n",
    "\n",
    "![卷积尺寸计算](./fig/conv_cal.png)\n",
    "![常用尺寸](./fig/conv_settings.png)\n",
    "\n",
    "### 池化：让表示尺寸更小，易于处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 激活函数的选择\n",
    "![激活函数的选择](./fig/act_chose.png)\n",
    "\n",
    "### 数据预处理\n",
    "![数据预处理](./fig/datapro.png)\n",
    "\n",
    "### 权重初始化\n",
    "![权重初始化1](./fig/weight_pro1.png)\n",
    "\n",
    "### xavier初始化\n",
    "![XAVIER](./fig/XAVIER.png)\n",
    "\n",
    "### 批量归一化\n",
    "#### 作用：把输入限制在非线性函数的线性区域内\n",
    "![批量归一化](./fig/batchnor.png)\n",
    "![批量归一化位置](./fig/batchpos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常见问题分析\n",
    "### loss基本不下降：学习率太低\n",
    "### cost为NAN：学习率太高\n",
    "\n",
    "### 学习率通常设置在1e-3到1e-5之间\n",
    "![参数选择区间](./fig/paramchose.png)\n",
    "![问题分析](./fig/problem.png)\n",
    "![问题分析1](./fig/problem1.png)\n",
    "![问题分析2](./fig/problem2.png)\n",
    "![问题分析3](./fig/problem3.png)\n",
    "![总结1](./fig/summary1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 优化\n",
    "![动量SGD](./fig/SGD+MOM.png)\n",
    "![Nest](./fig/nest.png)\n",
    "![ADA](./fig/ADA+RMS.png)\n",
    "![ADAM](./fig/ADAM.png)\n",
    "### 尽管adam性能通常更好，但存在第一次更新时第二梯度接近于零，并作为分母，导致变化过大的问题，故有改进：\n",
    "![ADAM改](./fig/adam_ex.png)\n",
    "![学习率衰减](./fig/rate_dec.png)\n",
    "\n",
    "### 对于衰减学习率，动量SGD经常用，adam很少用\n",
    "### 实践策略：先不衰减，用一个不错的初始学习率进行实验，然后根据loss曲线决定从哪开始衰减\n",
    "\n",
    "![总结2](./fig/summary2.png)\n",
    "![集成](./fig/ensemble.png)\n",
    "![小技巧](./fig/polyak.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正则化\n",
    "![正则化](./fig/reg.png)\n",
    "\n",
    "# dropout\n",
    "### 在卷积层的dropout往往是将某个通道整个置零\n",
    "![dropout的测试阶段](./fig/dropout_test.png)\n",
    "\n",
    "# 数据增强\n",
    "![数据增强](./fig/data_aug.png)\n",
    "\n",
    "![总结3](./fig/summary3.png)\n",
    "\n",
    "# 核心：引入随机性\n",
    "# 一般来说batch normalization比较好，还能帮助网络收敛"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 迁移学习\n",
    "![迁移学习](./fig/transfer.png)\n",
    "![迁移学习1](./fig/transfer1.png)\n",
    "![预训练模型](./fig/model_zoo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN\n",
    "\n",
    "![RNN结构](./fig/RNN.png)\n",
    "![RNN](./fig/vanilla_RNN.png)\n",
    "![RNN计算图](./fig/RNN_CG.png)\n",
    "![seq2seq](./fig/seq2seq.png)\n",
    "![RNN反向传播](./fig/truncated_bp.png)\n",
    "![multrcnn](./fig/mult_rcnns.png)\n",
    "### tips：一般来说两到三层足矣\n",
    "![rcc梯度流](./fig/rnn_gradflow.png)\n",
    "![rcc梯度流1](./fig/rnn_gradflow1.png)\n",
    "![LSTM](./fig/LSTM.png)\n",
    "![LSTM1](./fig/LSTM1.png)\n",
    "![LSTM梯度流](./fig/LSTM_gradflow.png)\n",
    "![GRU](./fig/GRU.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 识别与分割\n",
    "\n",
    "## tips:loss的选择\n",
    "### 连续值：L1, L2, smooth L1\n",
    "### 间隔值：SVM loss, cross, softmax\n",
    "![目标检测](./fig/OD.PNG)\n",
    "![mask rcnn](./fig/mask.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图像目标检测和图像分割\n",
    "\n",
    "## 上采样方法\n",
    "### unpooling去池化\n",
    "![unpooling](./fig/unpooling.PNG)\n",
    "![max unpooling](./fig/max_unpool.PNG)\n",
    "![转置卷积](./fig/transpose_conv.PNG)\n",
    "\n",
    "![图像分割](./fig/seg.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化和理解\n",
    "\n",
    "![可视化](./fig/gradient_ascent.png)\n",
    "![fool](./fig/fool.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成模型\n",
    "\n",
    "![对比](./fig/sup_vs_unsup.png)\n",
    "![概览图](./fig/gen.png)\n",
    "![pixelrnn](./fig/pixel_rnn.png)\n",
    "![pixelcnn](./fig/pixel_cnn.png)\n",
    "\n",
    "## 变分自编码器VAEs\n",
    "![auto1](./fig/auto1.png)\n",
    "![auto2](./fig/auto2.png)\n",
    "![auto3](./fig/auto3.png)\n",
    "![auto4](./fig/auto4.png)\n",
    "![auto5](./fig/auto5.png)\n",
    "![VAEs1](./fig/VAEs1.png)\n",
    "![VAEs2](./fig/VAEs2.png)\n",
    "![VAEs3](./fig/VAEs3.png)\n",
    "![VAEs4](./fig/VAEs4.png)\n",
    "![VAEs5](./fig/VAEs5.png)\n",
    "![VAEs6](./fig/VAEs6.png)\n",
    "### z可用作下游任务的特征\n",
    "![VAEs7](./fig/VAEs7.png)\n",
    "\n",
    "## GANs\n",
    "![GAN1](./fig/GAN1.png)\n",
    "![GAN2](./fig/GAN2.png)\n",
    "![GAN3](./fig/GAN3.png)\n",
    "![GAN4](./fig/GAN4.png)\n",
    "![GAN5](./fig/GAN5.png)\n",
    "![GAN6](./fig/GAN6.png)\n",
    "![GAN7](./fig/GAN7.png)\n",
    "\n",
    "![小结4](./fig/summary4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 强化学习\n",
    "\n",
    "![RL1](./fig/RL1.PNG)\n",
    "![马尔科夫决策](./fig/Markov.PNG)\n",
    "![马尔科夫决策1](./fig/Markov1.PNG)\n",
    "![opt_policy](./fig/opt_policy.PNG)\n",
    "![def](./fig/def.PNG)\n",
    "![bellman](./fig/bellman.PNG)\n",
    "![solve](./fig/solve.PNG)\n",
    "\n",
    "# Q-learning\n",
    "![Q1](./fig/Q1.PNG)\n",
    "![q_pass](./fig/q_pass.PNG)\n",
    "![q_arch](./fig/q_arch.PNG)\n",
    "![exp_reply](./fig/exp_reply.PNG)\n",
    "![q_alg](./fig/q_alg.PNG)\n",
    "![RL2](./fig/RL2.PNG)\n",
    "![Q3](./fig/Q3.PNG)\n",
    "![Q4](./fig/Q4.PNG)\n",
    "![Q5](./fig/Q5.PNG)\n",
    "![Q6](./fig/Q6.PNG)\n",
    "![Q7](./fig/Q7.PNG)\n",
    "![Q8](./fig/Q8.PNG)\n",
    "![Q9](./fig/Q9.PNG)\n",
    "![Q10](./fig/Q10.PNG)\n",
    "![Q11](./fig/Q11.PNG)\n",
    "![小结5](./fig/summary5.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
